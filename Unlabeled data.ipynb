{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with unlabeled data (Semi-supervised learning)\n",
    "### Case Study (MNIST-Fashion dataset)\n",
    "### by Mehmet Solmaz, August 2018\n",
    "\n",
    "#### Problem definition: Given a huge dataset, only a small part of which is assigned a known label (out of a set of N), and also given a human labeler that comes at a cost. How to build a classifier while minimizing the cost?\n",
    "#### In other words, formally given: <br> (1) A small dataset with (x,y) pairs,<br> (2) Large dataset with (x,) pairs. <br> Our goal is to find a better classifier than from just the labeled data alone. \n",
    "\n",
    "Firstly, this problem is between Supervised and Unsupervised Learning algorithms (Semi-supervised). We only have certain amount of labeled data. In the case of Big Data, the percentage of labeled data could be less than 1%. Even if we get a human labeler at a certain cost, we might not be able to label each data point.<br>\n",
    "Here are some approaches to be considered:\n",
    "\n",
    "1- First approach could be using the small subset of data for training, and use it to label the rest of the unlabeled data. Then use it to retrain the whole dataset and build a model <br>\n",
    "2- Second approach could be using Clustering on the dataset. We can decide the class by looking at the majority of labeled data points in that cluster. \n",
    "\n",
    "In this notebook, I have tried to simulate the first approach on an MNIST-Fashion image dataset. Image dataset was chosen because they require a human labeler for classification purposes.<br>\n",
    "\n",
    "MNIST-Fashion dataset comes with all the data labeled. To mimick a semi-supervised learning problem, I have deliberately removed certain percentages (99%, 95%, 90%, and 80%) of data and built classifiers with minimal data. That is, I have built classifiers with 1%, 5%, 10%, 20% of the initial data while randomly removing the rest. At each time, I have predicted the labels of unused data using the ML model, and compared with the Ground Truth (already labeled data). I have also built a classifier using 100% of the data and obtained performance metrics. \n",
    "\n",
    "For each classifier, I recorded the f1-scores, which were later used in Curve-Fitting to obtain a trend between Used Data Percentage and f1-score. The fitted function (logarithmic) reveals that there is a inflexion point where the increase in f1-score slows down. In this experiment, the inflexion point is around 15%. This point can be used as the minimum performance point to be reached via the help of human labelers. \n",
    "\n",
    "To sum up, to minimize the cost associated with human labelers, they should be used to add labels to the dataset only in the large performance increment regime. If the performance of the classifier starts slowing down at consecutive increments, this is the point to stop human labeling because there may not be any substantial improvement in classification performance.\n",
    "\n",
    "__Footnote__: Another dataset may not show the same behavior as MNIST. From what I have gathered from the literature, datasets with high quality labels are more suitable for this approach. MNIST is one of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline\n",
    "# import the necessary packages\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28) y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", X_test.shape, \"y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example image from class 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noBh+okD9H5/FeKoXZRZ/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1231a2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show one of the images from the training dataset\n",
    "index = 233\n",
    "plt.imshow(x_train[index,:,:])\n",
    "print (\"Example image from class \" + str(np.squeeze(y_train[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1) y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28, 1) y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", X_test.shape, \"y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into Train, and Validation \n",
    "# Use test for prediction\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 48000\n",
      "number of test examples = 10000\n",
      "number of validation examples = 12000\n",
      "X_train shape: (48000, 28, 28, 1)\n",
      "Y_train shape: (48000, 10)\n",
      "X_test shape: (10000, 28, 28, 1)\n",
      "Y_test shape: (10000, 10)\n",
      "X_val shape: (12000, 28, 28, 1)\n",
      "Y_val shape: (12000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.divide(X_train,255)\n",
    "X_test = np.divide(X_test,255)\n",
    "X_val = np.divide(X_val,255)\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_test = to_categorical(Y_test)\n",
    "Y_val = to_categorical(Y_val)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 122,922\n",
      "Trainable params: 122,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-03, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 110s 2ms/step - loss: 0.7564 - acc: 0.7177 - val_loss: 0.4531 - val_acc: 0.8425\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 109s 2ms/step - loss: 0.4862 - acc: 0.8215 - val_loss: 0.3646 - val_acc: 0.8658\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 106s 2ms/step - loss: 0.4170 - acc: 0.8482 - val_loss: 0.3250 - val_acc: 0.8809\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.3818 - acc: 0.8596 - val_loss: 0.3172 - val_acc: 0.8839\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.3599 - acc: 0.8679 - val_loss: 0.3044 - val_acc: 0.8883\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 91s 2ms/step - loss: 0.3460 - acc: 0.8723 - val_loss: 0.2865 - val_acc: 0.8949\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 92s 2ms/step - loss: 0.3316 - acc: 0.8780 - val_loss: 0.2841 - val_acc: 0.8945\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.3225 - acc: 0.8818 - val_loss: 0.2753 - val_acc: 0.8982\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 91s 2ms/step - loss: 0.3110 - acc: 0.8846 - val_loss: 0.2665 - val_acc: 0.9032\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 91s 2ms/step - loss: 0.3068 - acc: 0.8854 - val_loss: 0.2580 - val_acc: 0.9043\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2974 - acc: 0.8896 - val_loss: 0.2851 - val_acc: 0.8922\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2943 - acc: 0.8911 - val_loss: 0.2592 - val_acc: 0.9023\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 91s 2ms/step - loss: 0.2918 - acc: 0.8914 - val_loss: 0.2535 - val_acc: 0.9058\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 93s 2ms/step - loss: 0.2843 - acc: 0.8935 - val_loss: 0.2535 - val_acc: 0.9064\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 90s 2ms/step - loss: 0.2786 - acc: 0.8961 - val_loss: 0.2515 - val_acc: 0.9059\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 102s 2ms/step - loss: 0.2773 - acc: 0.8953 - val_loss: 0.2495 - val_acc: 0.9042\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 108s 2ms/step - loss: 0.2758 - acc: 0.8967 - val_loss: 0.2432 - val_acc: 0.9082\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 109s 2ms/step - loss: 0.2706 - acc: 0.8998 - val_loss: 0.2445 - val_acc: 0.9087\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 107s 2ms/step - loss: 0.2664 - acc: 0.8992 - val_loss: 0.2407 - val_acc: 0.9087\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 91s 2ms/step - loss: 0.2671 - acc: 0.9013 - val_loss: 0.2450 - val_acc: 0.9062\n"
     ]
    }
   ],
   "source": [
    "my_model = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Acquired: 0.9032\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy Acquired:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_acc', 'loss', 'val_loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(my_model.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEeCAYAAACpGzMjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149738048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEeCAYAAAB/vulGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny+QkYWZmmZwkzMwsk5OEmZll+v+Fm8Bc+TGmtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149742b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(my_model.history['acc'], 'bo')\n",
    "plt.plot(my_model.history['val_acc'], 'rs')\n",
    "plt.title('model accuracy', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.savefig('accuracy_vs_epoch.png')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(my_model.history['loss'], 'bo')\n",
    "plt.plot(my_model.history['val_loss'], 'rs')\n",
    "plt.title('model loss', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=14)\n",
    "plt.xlabel('epoch', fontsize=14)\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.86      0.86      1000\n",
      "          1       0.98      0.98      0.98      1000\n",
      "          2       0.87      0.83      0.85      1000\n",
      "          3       0.92      0.89      0.91      1000\n",
      "          4       0.80      0.89      0.85      1000\n",
      "          5       0.99      0.97      0.98      1000\n",
      "          6       0.72      0.70      0.71      1000\n",
      "          7       0.94      0.97      0.96      1000\n",
      "          8       0.98      0.98      0.98      1000\n",
      "          9       0.97      0.96      0.96      1000\n",
      "\n",
      "avg / total       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(Y_test,axis=1),predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_f1_score_100 = 0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets start building a new classifier with only 1% of the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload the data\n",
    "(x_train, y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate Train and Test set\n",
    "X = np.concatenate((x_train, X_test),axis=0)\n",
    "Y = np.concatenate((y_train, Y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (70000, 28, 28) Y shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape, \"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x110bd66a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x149604f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y, bins='auto')\n",
    "plt.title(\"Training Label Histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Each class has 7000 data points, when train and test are combined__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is small preprocessor function that find the class labels and replaces Certain percentage\n",
    "# of each class with label 10\n",
    "# I picked label 10 because it doesn't exist among the labels.\n",
    "def remove_labels_randomly(Y,percntage):\n",
    "    y_new = np.copy(Y)\n",
    "    for i in range(0,10):\n",
    "        # find the index of i's\n",
    "        my_bin = list(np.where(Y == i))\n",
    "        # calculate the percentage of data to be processed\n",
    "        my_percentage = percntage\n",
    "        num_iterations = int(len(my_bin[0])*my_percentage)\n",
    "        # generate random numbers in range of my_bin and the size of num_iterations\n",
    "        my_index = np.random.choice(range(len(my_bin[0])), num_iterations, replace=False)\n",
    "        for j in range(0,num_iterations):\n",
    "            new_index = my_bin[0][(my_index[j])]\n",
    "            y_new[new_index] = 10\n",
    "    return y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new training label with 1% of labels left (99% removed randomly)\n",
    "y_01 = remove_labels_randomly(Y,0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 99% of labels are 10\n",
    "remove_99_percent = list(np.where(y_01 == 10))\n",
    "# 1% of the labels are from 0-9\n",
    "leave_01_percent = list(np.where(y_01 != 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove_99_percent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 99% of the labels in the original labels are saved for future\n",
    "y_99 = np.delete(Y, leave_01_percent)\n",
    "# 1% of the labels\n",
    "y_01 = np.delete(y_01, remove_99_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1% of the feature set\n",
    "x_01 = np.delete(X, remove_99_percent,0)\n",
    "# 99% of the feature set\n",
    "x_99 = np.delete(X, leave_01_percent,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 28, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69300, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_99.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_01 = x_01.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 1% of the data for building a model\n",
    "# Split the data into Train, Test, and Validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_01, y_01, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 448\n",
      "number of test examples = 140\n",
      "number of validation examples = 112\n",
      "X_train shape: (448, 28, 28, 1)\n",
      "Y_train shape: (448, 10)\n",
      "X_test shape: (140, 28, 28, 1)\n",
      "Y_test shape: (140, 10)\n",
      "X_val shape: (112, 28, 28, 1)\n",
      "Y_val shape: (112, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.divide(X_train,255)\n",
    "X_test = np.divide(X_test,255)\n",
    "X_val = np.divide(X_val,255)\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "Y_val = to_categorical(y_val)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model for 5% labeled data\n",
    "model_01 = Sequential()\n",
    "model_01.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
    "model_01.add(Activation('relu'))\n",
    "model_01.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_01.add(Dropout(0.25))\n",
    "\n",
    "model_01.add(Conv2D(32, (3, 3)))\n",
    "model_01.add(Activation('relu'))\n",
    "model_01.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_01.add(Dropout(0.25))\n",
    "\n",
    "model_01.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_01.add(Dense(128, activation='relu'))\n",
    "model_01.add(Dropout(0.5))\n",
    "model_01.add(Dense(10, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               102528    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 122,922\n",
      "Trainable params: 122,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_01.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-03, decay=0.0)\n",
    "model_01.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 448 samples, validate on 112 samples\n",
      "Epoch 1/20\n",
      "448/448 [==============================] - 2s 4ms/step - loss: 2.2862 - acc: 0.1295 - val_loss: 2.2370 - val_acc: 0.3036\n",
      "Epoch 2/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.2176 - acc: 0.1808 - val_loss: 2.1286 - val_acc: 0.4643\n",
      "Epoch 3/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 2.0521 - acc: 0.2746 - val_loss: 1.8794 - val_acc: 0.5268\n",
      "Epoch 4/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.8498 - acc: 0.3638 - val_loss: 1.5407 - val_acc: 0.5446\n",
      "Epoch 5/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.6585 - acc: 0.4241 - val_loss: 1.3832 - val_acc: 0.5625\n",
      "Epoch 6/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.5050 - acc: 0.4554 - val_loss: 1.2528 - val_acc: 0.5714\n",
      "Epoch 7/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.4331 - acc: 0.4754 - val_loss: 1.1769 - val_acc: 0.5714\n",
      "Epoch 8/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.3534 - acc: 0.4821 - val_loss: 1.1120 - val_acc: 0.5893\n",
      "Epoch 9/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2823 - acc: 0.5268 - val_loss: 1.1002 - val_acc: 0.6607\n",
      "Epoch 10/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.2143 - acc: 0.5580 - val_loss: 0.9963 - val_acc: 0.6429\n",
      "Epoch 11/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.1676 - acc: 0.5804 - val_loss: 0.9986 - val_acc: 0.6696\n",
      "Epoch 12/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0684 - acc: 0.6071 - val_loss: 0.9533 - val_acc: 0.6964\n",
      "Epoch 13/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 1.0283 - acc: 0.6228 - val_loss: 0.8861 - val_acc: 0.6696\n",
      "Epoch 14/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.9878 - acc: 0.6272 - val_loss: 0.8639 - val_acc: 0.7143\n",
      "Epoch 15/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.9823 - acc: 0.6317 - val_loss: 0.8794 - val_acc: 0.6964\n",
      "Epoch 16/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.9238 - acc: 0.6295 - val_loss: 0.8632 - val_acc: 0.6964\n",
      "Epoch 17/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.8639 - acc: 0.6808 - val_loss: 0.8597 - val_acc: 0.7143\n",
      "Epoch 18/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.8266 - acc: 0.7031 - val_loss: 0.8004 - val_acc: 0.7143\n",
      "Epoch 19/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.8169 - acc: 0.6942 - val_loss: 0.7954 - val_acc: 0.6964\n",
      "Epoch 20/20\n",
      "448/448 [==============================] - 1s 2ms/step - loss: 0.7902 - acc: 0.7054 - val_loss: 0.7640 - val_acc: 0.6964\n"
     ]
    }
   ],
   "source": [
    "my_model_01 = model_01.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Acquired: 0.692857142857\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_01.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy Acquired:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_99_reshaped = x_99.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69300, 28, 28, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_99_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_99 = model_01.predict_classes(x_99_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.82      0.73      6930\n",
      "          1       0.91      0.95      0.93      6930\n",
      "          2       0.56      0.61      0.59      6930\n",
      "          3       0.79      0.61      0.68      6930\n",
      "          4       0.49      0.81      0.61      6930\n",
      "          5       0.98      0.66      0.79      6930\n",
      "          6       0.31      0.08      0.12      6930\n",
      "          7       0.76      0.77      0.77      6930\n",
      "          8       0.93      0.89      0.91      6930\n",
      "          9       0.75      0.98      0.85      6930\n",
      "\n",
      "avg / total       0.71      0.72      0.70     69300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_99, predictions_99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_f1_score_01 = 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets start building a new classifier with only 5% of the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload the data\n",
    "(x_train, y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate Train and Test set\n",
    "X = np.concatenate((x_train, X_test),axis=0)\n",
    "Y = np.concatenate((y_train, Y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new training label with 5% of labels left (95% removed randomly)\n",
    "y_05 = remove_labels_randomly(Y,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 95% of labels are 10\n",
    "remove_95_percent = list(np.where(y_05 == 10))\n",
    "# 5% of the labels are from 0-9\n",
    "leave_05_percent = list(np.where(y_05 != 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 95% of the labels in the original labels are saved for future\n",
    "y_95 = np.delete(Y, leave_05_percent)\n",
    "# 5% of the labels\n",
    "y_05 = np.delete(y_05, remove_95_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5% of the feature set\n",
    "x_05 = np.delete(X, remove_95_percent,0)\n",
    "# 95% of the feature set\n",
    "x_95 = np.delete(X, leave_05_percent,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 28, 28)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66500, 28, 28)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_95.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_05 = x_05.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 5% of the data for building a model\n",
    "# Split the data into Train, Test, and Validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_05, y_05, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 2240\n",
      "number of test examples = 700\n",
      "number of validation examples = 560\n",
      "X_train shape: (2240, 28, 28, 1)\n",
      "Y_train shape: (2240, 10)\n",
      "X_test shape: (700, 28, 28, 1)\n",
      "Y_test shape: (700, 10)\n",
      "X_val shape: (560, 28, 28, 1)\n",
      "Y_val shape: (560, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.divide(X_train,255)\n",
    "X_test = np.divide(X_test,255)\n",
    "X_val = np.divide(X_val,255)\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "Y_val = to_categorical(y_val)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model for 5% labeled data\n",
    "model_05 = Sequential()\n",
    "model_05.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
    "model_05.add(Activation('relu'))\n",
    "model_05.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_05.add(Dropout(0.25))\n",
    "\n",
    "model_05.add(Conv2D(32, (3, 3)))\n",
    "model_05.add(Activation('relu'))\n",
    "model_05.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_05.add(Dropout(0.25))\n",
    "\n",
    "model_05.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_05.add(Dense(128, activation='relu'))\n",
    "model_05.add(Dropout(0.5))\n",
    "model_05.add(Dense(10, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-03, decay=0.0)\n",
    "model_05.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2240 samples, validate on 560 samples\n",
      "Epoch 1/20\n",
      "2240/2240 [==============================] - 5s 2ms/step - loss: 2.0435 - acc: 0.2616 - val_loss: 1.3654 - val_acc: 0.5054\n",
      "Epoch 2/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 1.2786 - acc: 0.5357 - val_loss: 0.9022 - val_acc: 0.6964\n",
      "Epoch 3/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 1.0106 - acc: 0.6357 - val_loss: 0.7924 - val_acc: 0.7125\n",
      "Epoch 4/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.8621 - acc: 0.6888 - val_loss: 0.6885 - val_acc: 0.7482\n",
      "Epoch 5/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.7915 - acc: 0.7161 - val_loss: 0.6621 - val_acc: 0.7518\n",
      "Epoch 6/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.7450 - acc: 0.7313 - val_loss: 0.6545 - val_acc: 0.7589\n",
      "Epoch 7/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.6858 - acc: 0.7455 - val_loss: 0.6216 - val_acc: 0.7750\n",
      "Epoch 8/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.6765 - acc: 0.7527 - val_loss: 0.6079 - val_acc: 0.7750\n",
      "Epoch 9/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.6411 - acc: 0.7531 - val_loss: 0.6165 - val_acc: 0.7714\n",
      "Epoch 10/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.6328 - acc: 0.7647 - val_loss: 0.5938 - val_acc: 0.7750\n",
      "Epoch 11/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.6058 - acc: 0.7772 - val_loss: 0.5831 - val_acc: 0.7804\n",
      "Epoch 12/20\n",
      "2240/2240 [==============================] - 5s 2ms/step - loss: 0.5858 - acc: 0.7754 - val_loss: 0.5553 - val_acc: 0.7893\n",
      "Epoch 13/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5871 - acc: 0.7804 - val_loss: 0.5491 - val_acc: 0.7857\n",
      "Epoch 14/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5509 - acc: 0.7871 - val_loss: 0.5596 - val_acc: 0.7982\n",
      "Epoch 15/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5569 - acc: 0.7817 - val_loss: 0.5203 - val_acc: 0.7946\n",
      "Epoch 16/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5305 - acc: 0.8036 - val_loss: 0.5273 - val_acc: 0.8268\n",
      "Epoch 17/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5210 - acc: 0.8121 - val_loss: 0.5363 - val_acc: 0.7982\n",
      "Epoch 18/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5126 - acc: 0.8054 - val_loss: 0.5133 - val_acc: 0.8232\n",
      "Epoch 19/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.4837 - acc: 0.8161 - val_loss: 0.5291 - val_acc: 0.8054\n",
      "Epoch 20/20\n",
      "2240/2240 [==============================] - 4s 2ms/step - loss: 0.5027 - acc: 0.8183 - val_loss: 0.5026 - val_acc: 0.8179\n"
     ]
    }
   ],
   "source": [
    "my_model_05 = model_05.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Acquired: 0.802857142517\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_05.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy Acquired:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_95_reshaped = x_95.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_95 = model_05.predict_classes(x_95_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.83      0.78      6650\n",
      "          1       0.94      0.97      0.95      6650\n",
      "          2       0.66      0.70      0.68      6650\n",
      "          3       0.82      0.83      0.82      6650\n",
      "          4       0.57      0.87      0.69      6650\n",
      "          5       0.96      0.92      0.94      6650\n",
      "          6       0.60      0.11      0.19      6650\n",
      "          7       0.93      0.89      0.91      6650\n",
      "          8       0.92      0.95      0.93      6650\n",
      "          9       0.90      0.96      0.93      6650\n",
      "\n",
      "avg / total       0.80      0.80      0.78     66500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_95, predictions_95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_f1_score_05 = 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets start building a new classifier with only 10% of the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload the data\n",
    "(x_train, y_train), (X_test, Y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Train and Test set\n",
    "X = np.concatenate((x_train, X_test),axis=0)\n",
    "Y = np.concatenate((y_train, Y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_10 = remove_labels_randomly(Y,0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 90% of labels are 10\n",
    "remove_90_percent = list(np.where(y_10 == 10))\n",
    "# 10% of the labels are from 0-9\n",
    "leave_10_percent = list(np.where(y_10 != 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 90% of the labels in the original labels are saved for future\n",
    "y_90 = np.delete(Y, leave_10_percent)\n",
    "# 10% of the labels\n",
    "y_10 = np.delete(y_10, remove_90_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of the feature set\n",
    "x_10 = np.delete(X, remove_90_percent,0)\n",
    "# 90% of the feature set\n",
    "x_90 = np.delete(X, leave_10_percent,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7000, 28, 28)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63000, 28, 28)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_90.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_10 = x_10.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 10% of the data for building a model\n",
    "# Split the data into Train, Test, and Validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_10, y_10, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 4480\n",
      "number of test examples = 1400\n",
      "number of validation examples = 1120\n",
      "X_train shape: (4480, 28, 28, 1)\n",
      "Y_train shape: (4480, 10)\n",
      "X_test shape: (1400, 28, 28, 1)\n",
      "Y_test shape: (1400, 10)\n",
      "X_val shape: (1120, 28, 28, 1)\n",
      "Y_val shape: (1120, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.divide(X_train,255)\n",
    "X_test = np.divide(X_test,255)\n",
    "X_val = np.divide(X_val,255)\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "Y_val = to_categorical(y_val)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model for 10% labeled data\n",
    "model_10 = Sequential()\n",
    "model_10.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Conv2D(32, (3, 3)))\n",
    "model_10.add(Activation('relu'))\n",
    "model_10.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_10.add(Dropout(0.25))\n",
    "\n",
    "model_10.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_10.add(Dense(128, activation='relu'))\n",
    "model_10.add(Dropout(0.5))\n",
    "model_10.add(Dense(10, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-03, decay=0.0)\n",
    "model_10.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4480 samples, validate on 1120 samples\n",
      "Epoch 1/20\n",
      "4480/4480 [==============================] - 10s 2ms/step - loss: 1.7283 - acc: 0.3482 - val_loss: 0.9867 - val_acc: 0.6813\n",
      "Epoch 2/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.9966 - acc: 0.6368 - val_loss: 0.7184 - val_acc: 0.7375\n",
      "Epoch 3/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.7868 - acc: 0.7121 - val_loss: 0.6108 - val_acc: 0.7705\n",
      "Epoch 4/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.7006 - acc: 0.7411 - val_loss: 0.5626 - val_acc: 0.7911\n",
      "Epoch 5/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.6510 - acc: 0.7549 - val_loss: 0.5238 - val_acc: 0.7946\n",
      "Epoch 6/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.6047 - acc: 0.7734 - val_loss: 0.4996 - val_acc: 0.8018\n",
      "Epoch 7/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.5720 - acc: 0.7848 - val_loss: 0.5000 - val_acc: 0.8152\n",
      "Epoch 8/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.5632 - acc: 0.7913 - val_loss: 0.4863 - val_acc: 0.8116\n",
      "Epoch 9/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.5348 - acc: 0.8009 - val_loss: 0.4734 - val_acc: 0.8152\n",
      "Epoch 10/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.5246 - acc: 0.8027 - val_loss: 0.4519 - val_acc: 0.8286\n",
      "Epoch 11/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4930 - acc: 0.8154 - val_loss: 0.4345 - val_acc: 0.8357\n",
      "Epoch 12/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4889 - acc: 0.8163 - val_loss: 0.4208 - val_acc: 0.8500\n",
      "Epoch 13/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4713 - acc: 0.8232 - val_loss: 0.4276 - val_acc: 0.8473\n",
      "Epoch 14/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4512 - acc: 0.8384 - val_loss: 0.3937 - val_acc: 0.8545\n",
      "Epoch 15/20\n",
      "4480/4480 [==============================] - 8s 2ms/step - loss: 0.4484 - acc: 0.8373 - val_loss: 0.3987 - val_acc: 0.8482\n",
      "Epoch 16/20\n",
      "4480/4480 [==============================] - 8s 2ms/step - loss: 0.4311 - acc: 0.8408 - val_loss: 0.3928 - val_acc: 0.8518\n",
      "Epoch 17/20\n",
      "4480/4480 [==============================] - 8s 2ms/step - loss: 0.4104 - acc: 0.8451 - val_loss: 0.3966 - val_acc: 0.8589\n",
      "Epoch 18/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4138 - acc: 0.8462 - val_loss: 0.3846 - val_acc: 0.8598\n",
      "Epoch 19/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.4081 - acc: 0.8527 - val_loss: 0.3753 - val_acc: 0.8634\n",
      "Epoch 20/20\n",
      "4480/4480 [==============================] - 9s 2ms/step - loss: 0.3851 - acc: 0.8554 - val_loss: 0.3801 - val_acc: 0.8580\n"
     ]
    }
   ],
   "source": [
    "my_model_10 = model_10.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Acquired: 0.859285713945\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_10.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy Acquired:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_90_reshaped = x_90.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_90 = model_10.predict_classes(x_90_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.81      0.81      6300\n",
      "          1       0.98      0.97      0.98      6300\n",
      "          2       0.74      0.80      0.77      6300\n",
      "          3       0.86      0.88      0.87      6300\n",
      "          4       0.72      0.77      0.74      6300\n",
      "          5       0.94      0.96      0.95      6300\n",
      "          6       0.66      0.54      0.60      6300\n",
      "          7       0.95      0.89      0.92      6300\n",
      "          8       0.96      0.96      0.96      6300\n",
      "          9       0.93      0.96      0.94      6300\n",
      "\n",
      "avg / total       0.85      0.85      0.85     63000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_90, predictions_90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_f1_score_10 = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets start building a new classifier with only 20% of the initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reload the data\n",
    "(x_train, y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Concatenate Train and Test set\n",
    "X = np.concatenate((x_train, X_test),axis=0)\n",
    "Y = np.concatenate((y_train, Y_test),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new training label with 20% of labels left (80% removed randomly)\n",
    "y_20 = np.copy(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_20 = remove_labels_randomly(Y,0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80% of labels are 10\n",
    "remove_80_percent = list(np.where(y_20 == 10))\n",
    "# 20% of the labels are from 0-9\n",
    "leave_20_percent = list(np.where(y_20 != 10))\n",
    "\n",
    "# 80% of the labels in the original labels are saved for future\n",
    "y_80 = np.delete(Y, leave_20_percent)\n",
    "# 10% of the labels\n",
    "y_20 = np.delete(y_20, remove_80_percent)\n",
    "\n",
    "# 20% of the feature set\n",
    "x_20 = np.delete(X, remove_80_percent,0)\n",
    "# 80% of the feature set\n",
    "x_80 = np.delete(X, leave_20_percent,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_20 = x_20.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use 20% of the data for building a model\n",
    "# Split the data into Train, Test, and Validation \n",
    "X_train, X_test, y_train, y_test = train_test_split(x_20, y_20, test_size=0.20, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 8960\n",
      "number of test examples = 2800\n",
      "number of validation examples = 2240\n",
      "X_train shape: (8960, 28, 28, 1)\n",
      "Y_train shape: (8960, 10)\n",
      "X_test shape: (2800, 28, 28, 1)\n",
      "Y_test shape: (2800, 10)\n",
      "X_val shape: (2240, 28, 28, 1)\n",
      "Y_val shape: (2240, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.divide(X_train,255)\n",
    "X_test = np.divide(X_test,255)\n",
    "X_val = np.divide(X_val,255)\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "Y_val = to_categorical(y_val)\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"number of validation examples = \" + str(X_val.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "print (\"X_val shape: \" + str(X_val.shape))\n",
    "print (\"Y_val shape: \" + str(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new model for 20% labeled data\n",
    "model_20 = Sequential()\n",
    "model_20.add(Conv2D(64, (3, 3), input_shape=(28, 28, 1)))\n",
    "model_20.add(Activation('relu'))\n",
    "model_20.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_20.add(Dropout(0.25))\n",
    "\n",
    "model_20.add(Conv2D(32, (3, 3)))\n",
    "model_20.add(Activation('relu'))\n",
    "model_20.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_20.add(Dropout(0.25))\n",
    "\n",
    "model_20.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model_20.add(Dense(128, activation='relu'))\n",
    "model_20.add(Dropout(0.5))\n",
    "model_20.add(Dense(10, activation='softmax')) # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-03, decay=0.0)\n",
    "model_20.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8960 samples, validate on 2240 samples\n",
      "Epoch 1/20\n",
      "8960/8960 [==============================] - 18s 2ms/step - loss: 1.3163 - acc: 0.5202 - val_loss: 0.7132 - val_acc: 0.7446\n",
      "Epoch 2/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.7289 - acc: 0.7277 - val_loss: 0.6010 - val_acc: 0.7719\n",
      "Epoch 3/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.6366 - acc: 0.7680 - val_loss: 0.5403 - val_acc: 0.7978\n",
      "Epoch 4/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.5773 - acc: 0.7821 - val_loss: 0.5115 - val_acc: 0.7987\n",
      "Epoch 5/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.5422 - acc: 0.7925 - val_loss: 0.4847 - val_acc: 0.8129\n",
      "Epoch 6/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.5059 - acc: 0.8055 - val_loss: 0.4733 - val_acc: 0.8107\n",
      "Epoch 7/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.4791 - acc: 0.8232 - val_loss: 0.4387 - val_acc: 0.8299\n",
      "Epoch 8/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.4641 - acc: 0.8282 - val_loss: 0.4294 - val_acc: 0.8420\n",
      "Epoch 9/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.4438 - acc: 0.8298 - val_loss: 0.4117 - val_acc: 0.8549\n",
      "Epoch 10/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.4129 - acc: 0.8451 - val_loss: 0.3869 - val_acc: 0.8696\n",
      "Epoch 11/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.4052 - acc: 0.8471 - val_loss: 0.3919 - val_acc: 0.8585\n",
      "Epoch 12/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3962 - acc: 0.8502 - val_loss: 0.3893 - val_acc: 0.8558\n",
      "Epoch 13/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3819 - acc: 0.8550 - val_loss: 0.3683 - val_acc: 0.8665\n",
      "Epoch 14/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3650 - acc: 0.8608 - val_loss: 0.3613 - val_acc: 0.8701\n",
      "Epoch 15/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3617 - acc: 0.8628 - val_loss: 0.3513 - val_acc: 0.8795\n",
      "Epoch 16/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3446 - acc: 0.8647 - val_loss: 0.3508 - val_acc: 0.8781\n",
      "Epoch 17/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3360 - acc: 0.8723 - val_loss: 0.3467 - val_acc: 0.8777\n",
      "Epoch 18/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3314 - acc: 0.8751 - val_loss: 0.3542 - val_acc: 0.8799\n",
      "Epoch 19/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3233 - acc: 0.8754 - val_loss: 0.3708 - val_acc: 0.8625\n",
      "Epoch 20/20\n",
      "8960/8960 [==============================] - 17s 2ms/step - loss: 0.3239 - acc: 0.8776 - val_loss: 0.3416 - val_acc: 0.8835\n"
     ]
    }
   ],
   "source": [
    "my_model_20 = model_20.fit(X_train, Y_train, validation_data=(X_val, Y_val), batch_size=32, epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy Acquired: 0.8775\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model_20.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test accuracy Acquired:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_80_reshaped = x_80.reshape([-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 28, 28, 1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_80_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_80 = model_20.predict_classes(x_80_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.72      0.80      5600\n",
      "          1       0.99      0.97      0.98      5600\n",
      "          2       0.87      0.67      0.76      5600\n",
      "          3       0.90      0.88      0.89      5600\n",
      "          4       0.60      0.94      0.73      5600\n",
      "          5       0.94      0.98      0.96      5600\n",
      "          6       0.63      0.52      0.57      5600\n",
      "          7       0.97      0.88      0.92      5600\n",
      "          8       0.91      0.98      0.94      5600\n",
      "          9       0.93      0.97      0.95      5600\n",
      "\n",
      "avg / total       0.86      0.85      0.85     56000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_80, predictions_80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_f1_score_20 = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_score_list = [avg_f1_score_01,avg_f1_score_05,avg_f1_score_10,avg_f1_score_20,avg_f1_score_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.71, 0.78, 0.85, 0.85, 0.9]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_percentages = [1,5,10,20,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def funcLog(x, a, b):\n",
    "    return a+b*np.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(funcLog, data_percentages, f1_score_list, p0=(-1, 1))\n",
    "x_new = np.linspace(data_percentages[0], data_percentages[-1], 50)\n",
    "y_new = funcLog(x_new, *popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72123289,  0.04202542])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1351412b0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEOCAYAAACn00H/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6E8OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x133e08390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_percentages, f1_score_list, 'ro', x_new,y_new)\n",
    "plt.ylabel('f1-score', fontsize=14)\n",
    "plt.xlabel('Used Data (%)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
